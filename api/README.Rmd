---
title: "sentimentalk: Sentiment Analysis of Talk Pages as Service"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

[plumber](https://plumber.trestletech.com/)-based API for tidy sentiment analysis[^1] of [MediaWiki talk pages](https://www.mediawiki.org/wiki/Help:Talk_pages) on [MediaWiki](https://www.mediawiki.org/wiki/MediaWiki)-powered websites in R.

## Setup

```R
# install.packages("devtools")
devtools::install_github("bearloga/wmf-wmhack17/sentimentalk")
```

## Example

To analyze [Talk:Cross-wiki Search Result Improvements on MediaWiki](https://www.mediawiki.org/wiki/Talk:Cross-wiki_Search_Result_Improvements) we need to provide the API url "www.mediawiki.org/w/api.php"

### R

```{r example_r}
sentiment_breakdown <- sentimentalk::process(
  page_name = "Talk:Cross-wiki Search Result Improvements",
  api = "www.mediawiki.org/w/api.php"
)
str(sentiment_breakdown)
```

### Endpoint

We start the endpoint for local use via `Rscript endpoint.R`

#### GET

```{bash example_get}
curl -s -G \
  --data-urlencode "page_name=Talk:Cross-wiki Search Result Improvements" \
  --data-urlencode "api=www.mediawiki.org/w/api.php" \
  "http://localhost:8000/analyze"
```

#### POST

```{bash example_post}
curl -s \
  --data-urlencode "page_name=Talk:Cross-wiki Search Result Improvements" \
  --data-urlencode "api=www.mediawiki.org/w/api.php" \
  "http://localhost:8000/analyze"
```

#### POST with JSON data

```{bash example_json}
curl -s \
  --data '{"page_name":"Talk:Cross-wiki Search Result Improvements", "api":"www.mediawiki.org/w/api.php"}' \
  "http://localhost:8000/analyze"
```

## Additional Information

The sentiment analysis is performed using the National Research Council Canada (NRC) Word-Emotion Association Lexicon from Saif Mohammad and Peter Turney.[^2]

[^1]: http://tidytextmining.com/sentiment.html
[^2]: http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm
